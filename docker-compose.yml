services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    hostname: zookeeper
    container_name: zookeeper-tlng
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.3.0
    hostname: kafka
    container_name: kafka-tlng
    depends_on:
      - zookeeper
    ports:
      - "9093:9092"
      - "29092:29092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1

  kafka-init:
    image: confluentinc/cp-kafka:7.3.0
    depends_on:
      - kafka
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      echo 'Waiting for Kafka to be ready...'
      cub kafka-ready -b kafka:29092 1 30

      echo 'Creating topic log_submissions...'
      kafka-topics --create --if-not-exists --bootstrap-server kafka:29092 --partitions 6 --replication-factor 1 --topic log_submissions

      echo 'Topic created successfully!'
      "

  postgres:
    image: postgres:13-alpine
    hostname: postgres
    container_name: postgres-tlng
    environment:
      POSTGRES_USER: testuser
      POSTGRES_PASSWORD: secret
      POSTGRES_DB: testdb
    ports:
      - "5433:5432"
    volumes:
      - ~/docker-volumes/tlng-postgres-data:/var/lib/postgresql/data
      - ./scripts/db/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
      - ./scripts/db:/scripts
    restart: always

  ingestion:
    build:
      context: .
      dockerfile: cmd/ingestion/Dockerfile
    container_name: ingestion-service-tlng
    depends_on:
      - postgres
      - kafka
      - kafka-init
    # ports removed - only accessible via nginx
    environment:
      - TZ=Asia/Shanghai
    volumes:
      - ./config/ingestion.defaults.yml:/app/config/ingestion.defaults.yml
    restart: always

  engine:
    build:
      context: .
      dockerfile: cmd/engine/Dockerfile
    container_name: engine-service-tlng
    depends_on:
      - postgres
      - kafka
      - kafka-init
    environment:
      - TZ=Asia/Shanghai
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./config/engine.defaults.yml:/app/config/engine.defaults.yml
      - ./config/blockchain.defaults.yml:/app/config/blockchain.defaults.yml
      - ./config/clients:/app/config/clients
      # ChainMaker path from .env file
      - ${CHAINMAKER_PATH}:/app/chainmaker-go:ro
    restart: always

  query:
    build:
      context: .
      dockerfile: cmd/query/Dockerfile
    container_name: query-service-tlng
    depends_on:
      - postgres
    # ports removed - only accessible via nginx
    environment:
      - TZ=Asia/Shanghai
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - ./config/query.defaults.yml:/app/config/query.defaults.yml
      - ./config/blockchain.defaults.yml:/app/config/blockchain.defaults.yml
      - ./config/clients:/app/config/clients
      - ~/docker-volumes/tlng-query-logs:/var/log/query
      # ChainMaker path from .env file
      - ${CHAINMAKER_PATH}:/app/chainmaker-go:ro
    restart: always

  nginx:
    build:
      context: ./ingress
      dockerfile: Dockerfile
    container_name: nginx-gateway-tlng
    depends_on:
      - ingestion
      - query
    ports:
      - "80:80"      # HTTP
      - "443:443"    # HTTPS
      - "50052:50052"  # gRPC
    environment:
      - TZ=Asia/Shanghai
    volumes:
      - ./ingress/nginx/ssl:/etc/nginx/ssl:ro
      - ./ingress/nginx/conf.d:/etc/nginx/conf.d:ro
      - ./ingress/nginx/lua:/etc/nginx/lua:ro
      - ~/docker-volumes/tlng-nginx-logs:/var/log/nginx
    restart: always

  # Example Benthos (Redpanda Connect) adapter container
  # Default runs the Syslog adapter config; you can switch to
  # s3-processor.yml / kafka-consumer.yml by changing the command.
  benthos-syslog:
    image: redpandadata/connect:latest
    container_name: benthos-syslog-adapter
    depends_on:
      - ingestion
    ports:
      - "5514:5514/udp"  # Syslog UDP
      - "6514:6514/tcp"  # Syslog TCP
    volumes:
      - ./ingestion/adapters:/workspace/ingestion/adapters:ro
    working_dir: /workspace
    # The image entrypoint is redpanda-connect; we only need to pass args.
    command: [ "run", "/workspace/ingestion/adapters/syslog.yml" ]
    environment:
      - TZ=Asia/Shanghai
      - INGESTION_ENDPOINT=http://ingestion:8091/v1/logs
      - DEFAULT_ORG_ID=org-abc
      - SYSLOG_UDP_ADDR=0.0.0.0:5514
      - SYSLOG_TCP_ADDR=0.0.0.0:6514
      - HTTP_BATCH_COUNT=200
      - HTTP_BATCH_BYTES=200000
      - HTTP_BATCH_PERIOD=1s
    restart: unless-stopped
